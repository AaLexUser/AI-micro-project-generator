# LLM Configuration - Required
# Choose either OpenAI or Gemini and set the corresponding API key
AIPG_LLM_API_KEY=your-openai-or-gemini-api-key-here

# Optional: Override default model (default: openai/gpt-4o)
# For OpenAI: openai/gpt-4o, openai/gpt-4o-mini, openai/gpt-3.5-turbo
# For Gemini: gemini/gemini-2.0-flash, gemini/gemini-1.5-pro
AIPG_LLM_MODEL=openai/gpt-4o

# Optional: Custom LLM base URL (for self-hosted models)
# AIPG_LLM_BASE_URL=

# Langfuse Integration (Optional - for observability and tracing)
# Sign up at https://cloud.langfuse.com to get these keys
LANGFUSE_PUBLIC_KEY=your-langfuse-public-key-here
LANGFUSE_SECRET_KEY=your-langfuse-secret-key-here
LANGFUSE_HOST=https://cloud.langfuse.com

# RAG Configuration (Optional - uses defaults if not set)
AIPG_RAG_SIMILARITY_THRESHOLD=0.7
AIPG_RAG_K_CANDIDATES=5
AIPG_RAG_COLLECTION_NAME=micro_projects
AIPG_RAG_EMBEDDING_MODEL=gemini-embedding-001
# AIPG_RAG_EMBEDDING_API_KEY=  # If different from main LLM API key
# AIPG_RAG_EMBEDDING_BASE_URL=  # If using custom embedding service
# AIPG_RAG_CHROMA_PATH=  # Custom path for ChromaDB storage

# Sandbox Configuration (Optional - uses defaults if not set)
AIPG_SANDBOX_DOCKER_IMAGE=aipg-sandbox:latest
AIPG_SANDBOX_MEMORY_LIMIT=128m
AIPG_SANDBOX_CPU_QUOTA=0.5
AIPG_SANDBOX_PIDS_LIMIT=128
AIPG_SANDBOX_DEFAULT_TIMEOUT_SECONDS=5

# Application Environment (Optional - for deployment)
ENVIRONMENT=development
DEBUG=true
LOG_LEVEL=INFO
